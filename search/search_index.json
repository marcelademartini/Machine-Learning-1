{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"Arvore/main/","title":"Decision-Tree","text":""},{"location":"Arvore/main/#teste-arvore-de-decisao","title":"TESTE ARVORE DE DECIS\u00c3O","text":"outputcode <p>Accuracy: 0.76  2025-10-28T15:26:18.531705 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n\nplt.figure(figsize=(12, 10))\n\ndf = pd.read_csv('https://raw.githubusercontent.com/marcelademartini/Machine-Learning-1/refs/heads/main/Testing.csv')\n\n# Carregar o conjunto de dados\nx = df.drop(columns=['Outcome'])  # Use all features except the target\ny = df['Outcome']                 # Use the discrete class column as target\n\n# Dividir os dados em conjuntos de treinamento e teste\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\n# Avaliar o modelo\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\ntree.plot_tree(classifier)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre> outputcode <p>Accuracy: 0.77  2025-10-28T15:26:19.493543 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n# 1) Carregar e explorar dados\ndf = pd.read_csv('https://raw.githubusercontent.com/marcelademartini/Machine-Learning-1/refs/heads/main/Testing.csv')\n# df = pd.read_csv('/mnt/data/Training.csv')\n\n# (Explora\u00e7\u00e3o) df.describe(), df.dtypes, df.isna().sum() e df.head() ajudam a entender a base.\n\n# 2) Pr\u00e9-processamento\n# Se houver colunas categ\u00f3ricas:\n# le = LabelEncoder()\n# df['sua_coluna_categ'] = le.fit_transform(df['sua_coluna_categ'].astype(str))\n# Tratamento de nulos: df = df.fillna(df.median(numeric_only=True))  \n\n# 3) Divis\u00e3o em treino/teste\nx = df.drop(columns=['Outcome'])   # Features\ny = df['Outcome']                  # Alvo bin\u00e1rio\nx_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.2, random_state=42\n)\n\n# 4) Treinamento do modelo (Decision Tree)\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\n\n# 5) Avalia\u00e7\u00e3o (acur\u00e1cia + \u00e1rvore)\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Visualiza\u00e7\u00e3o da \u00e1rvore\nplt.figure(figsize=(12, 10))\ntree.plot_tree(classifier)\n# Para p\u00e1ginas HTML: exporta em SVG\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"Arvore/main/#codigo-1","title":"C\u00f3digo 1","text":""},{"location":"Arvore/main/#1-exploracao-dos-dados","title":"1) Explora\u00e7\u00e3o dos dados","text":"<ul> <li> <p>O c\u00f3digo carrega o arquivo CSV hospedado no GitHub em df usando pd.read_csv(...).</p> </li> <li> <p>A natureza do conjunto \u00e9 tratada de forma impl\u00edcita: parte-se do princ\u00edpio de que existe uma coluna alvo chamada Outcome e que as demais colunas s\u00e3o atributos preditores.</p> </li> </ul>"},{"location":"Arvore/main/#2-pre-processamento","title":"2) Pr\u00e9 processamento","text":"<ul> <li>O c\u00f3digo assume que as colunas de x s\u00e3o compat\u00edveis com o modelo (por exemplo, num\u00e9ricas ou j\u00e1 codificadas). </li> </ul>"},{"location":"Arvore/main/#3-divisao-dos-dados","title":"3) Divis\u00e3o dos dados","text":"<ul> <li> <p>As vari\u00e1veis s\u00e3o separadas em preditores e alvo:</p> </li> <li> <p>x = df.drop(columns=['Outcome']) cont\u00e9m todas as colunas exceto a coluna alvo.</p> </li> <li> <p>y = df['Outcome'] cont\u00e9m a classe discreta a ser prevista.</p> </li> <li> <p>A divis\u00e3o treino e teste \u00e9 feita por train_test_split(x, y, test_size=0.2, random_state=42), reservando 20% dos dados para teste e fixando a semente aleat\u00f3ria em 42 para reprodutibilidade.</p> </li> </ul>"},{"location":"Arvore/main/#4-treinamento-do-modelo","title":"4) Treinamento do modelo","text":"<ul> <li> <p>Cria se um classificador de \u00e1rvore de decis\u00e3o com tree.DecisionTreeClassifier() usando os padr\u00f5es da biblioteca (por exemplo, crit\u00e9rio Gini e profundidade livre, a menos que o dataset limite).</p> </li> <li> <p>O ajuste \u00e9 realizado com classifier.fit(x_train, y_train), aprendendo regras de decis\u00e3o a partir das amostras de treinamento.</p> </li> </ul>"},{"location":"Arvore/main/#5-avaliacao-do-modelo","title":"5) Avalia\u00e7\u00e3o do modelo","text":"<ul> <li> <p>O desempenho \u00e9 calculado com classifier.score(x_test, y_test), que retorna a acur\u00e1cia m\u00e9dia no conjunto de teste. O valor \u00e9 impresso com duas casas decimais por print(f\"Accuracy: {accuracy:.2f}\").</p> </li> <li> <p>A visualiza\u00e7\u00e3o da estrutura aprendida \u00e9 feita por tree.plot_tree(classifier), desenhando os n\u00f3s e divis\u00f5es na figura previamente aberta com plt.figure(figsize=(12, 10)).</p> </li> </ul>"},{"location":"Arvore/main/#6-relatorio-final-e-saida-grafica","title":"6) Relat\u00f3rio final e sa\u00edda gr\u00e1fica","text":"<ul> <li> <p>Para disponibilizar a figura em contexto HTML, o c\u00f3digo cria um StringIO, salva a figura atual em SVG com plt.savefig(buffer, format=\"svg\") e imprime o conte\u00fado do buffer com print(buffer.getvalue()).</p> </li> <li> <p>O resultado produzido pelo script \u00e9:</p> </li> <li> <p>a acur\u00e1cia calculada no conjunto de teste, e</p> </li> <li> <p>a \u00e1rvore de decis\u00e3o renderizada como SVG, impressa diretamente na sa\u00edda padr\u00e3o, pronta para ser consumida por uma p\u00e1gina que leia essa sa\u00edda e exiba o SVG.</p> </li> <li> <p>accuracy_score \u00e9 importado mas n\u00e3o \u00e9 utilizado, pois a acur\u00e1cia \u00e9 obtida via classifier.score(...).</p> </li> </ul>"},{"location":"Arvore/main/#codigo-2","title":"C\u00f3digo 2","text":""},{"location":"Arvore/main/#1-exploracao-dos-dados_1","title":"1) Explora\u00e7\u00e3o dos dados","text":"<ul> <li> <p>O script carrega a base diretamente da URL para o DataFrame df:</p> </li> <li> <p>df = pd.read_csv('https://raw.githubusercontent.com/.../Testing.csv')</p> </li> <li> <p>H\u00e1 coment\u00e1rios indicando as fun\u00e7\u00f5es de inspe\u00e7\u00e3o inicial: df.head() para amostra de linhas, df.dtypes para tipos por coluna, df.describe() para estat\u00edsticas descritivas e df.isna().sum() para contagem de ausentes.</p> </li> <li> <p>Nesta etapa o c\u00f3digo n\u00e3o imprime nada por padr\u00e3o, apenas aponta quais comandos usar para entender a natureza das vari\u00e1veis. A base cont\u00e9m a coluna alvo Outcome, usada mais adiante.</p> </li> </ul>"},{"location":"Arvore/main/#2-preprocessamento","title":"2) Preprocessamento","text":"<ul> <li> <p>O bloco de preprocessamento est\u00e1 comentado. Ele mostra como:</p> </li> <li> <p>Codificar categorias com LabelEncoder caso exista alguma coluna categ\u00f3rica.</p> </li> <li> <p>Tratar ausentes usando a mediana num\u00e9rica: df = df.fillna(df.median(numeric_only=True)).</p> </li> <li> <p>Como est\u00e1 escrito, o fluxo segue sem executar transforma\u00e7\u00f5es. Ou seja, o modelo utilizar\u00e1 os dados como est\u00e3o em df.</p> </li> </ul>"},{"location":"Arvore/main/#3-divisao-dos-dados_1","title":"3) Divis\u00e3o dos dados","text":"<ul> <li> <p>O c\u00f3digo separa features e alvo:</p> </li> <li> <p>x = df.drop(columns=['Outcome'])</p> </li> <li> <p>y = df['Outcome']</p> </li> <li> <p>Em seguida, faz a parti\u00e7\u00e3o treino e teste com propor\u00e7\u00e3o 80/20 e semente fixa para reprodutibilidade:</p> </li> <li> <p>x_train, x_test, y_train, y_test = train_test_split(     x, y, test_size=0.2, random_state=42 )</p> </li> <li> <p>Isso garante um conjunto de teste mantido para avalia\u00e7\u00e3o fora do treino.</p> </li> </ul>"},{"location":"Arvore/main/#4-treinamento-do-modelo-decision-tree","title":"4) Treinamento do modelo (Decision Tree)","text":"<ul> <li> <p>O classificador \u00e9 criado com random_state=42 e hiperpar\u00e2metros padr\u00e3o:</p> </li> <li> <p>classifier = tree.DecisionTreeClassifier(random_state=42)</p> </li> <li> <p>O ajuste do modelo ocorre com:</p> </li> <li> <p>classifier.fit(x_train, y_train)</p> </li> </ul>"},{"location":"Arvore/main/#5-avaliacao-do-modelo-e-visualizacao","title":"5) Avalia\u00e7\u00e3o do modelo e visualiza\u00e7\u00e3o","text":"<ul> <li> <p>A acur\u00e1cia \u00e9 calculada usando classifier.score(x_test, y_test) e exibida com duas casas decimais:</p> </li> <li> <p>accuracy = classifier.score(x_test, y_test) print(f\"Accuracy: {accuracy:.2f}\")</p> </li> <li> <p>Observa\u00e7\u00e3o descritiva: classifier.score em um classificador equivale \u00e0 acur\u00e1cia. O m\u00f3dulo tamb\u00e9m importou accuracy_score, mas a m\u00e9trica \u00e9 obtida via .score() no seu c\u00f3digo.</p> </li> </ul>"},{"location":"Arvore/main/#a-arvore-treinada-e-plotada","title":"* A \u00e1rvore treinada \u00e9 plotada:","text":"<p>plt.figure(figsize=(12, 10)) tree.plot_tree(classifier)</p> <ul> <li>O gr\u00e1fico apresenta a estrutura de decis\u00e3o aprendida, com informa\u00e7\u00f5es padr\u00e3o nos n\u00f3s como gini, amostras, distribui\u00e7\u00e3o por classe e classe final.</li> </ul>"},{"location":"Arvore/main/#para-uso-em-paginas-html-o-grafico-e-exportado-como-svg-para-um-buffer-de-texto-e-o-conteudo-svg-e-impresso","title":"* Para uso em p\u00e1ginas HTML, o gr\u00e1fico \u00e9 exportado como SVG para um buffer de texto e o conte\u00fado SVG \u00e9 impresso:","text":"<p>buffer = StringIO() plt.savefig(buffer, format=\"svg\") print(buffer.getvalue())</p> <ul> <li>Isso produz o markup SVG completo, pr\u00f3prio para incorpora\u00e7\u00e3o em HTML.</li> </ul>"},{"location":"Arvore/main/#6-relatorio-final","title":"6) Relat\u00f3rio final","text":"<ul> <li> <p>Com base no que o script produz, o relat\u00f3rio pode documentar:</p> </li> <li> <p>Dados e contexto: origem do Testing.csv e breve descri\u00e7\u00e3o das vari\u00e1veis observadas na explora\u00e7\u00e3o.</p> </li> <li> <p>Metodologia: uso de Decision Tree para classifica\u00e7\u00e3o com divis\u00e3o 80/20.</p> </li> <li> <p>Resultados: valor de acur\u00e1cia impresso pelo c\u00f3digo e a visualiza\u00e7\u00e3o da \u00e1rvore gerada em SVG.</p> </li> <li> <p>Discuss\u00e3o: leitura da estrutura da \u00e1rvore a partir do diagrama, destacando caminhos de decis\u00e3o e n\u00f3s mais relevantes conforme o gr\u00e1fico.</p> </li> <li> <p>O material gerado atende aos itens solicitados no template do projeto integrador: dados, m\u00e9todo, treinamento, m\u00e9trica de avalia\u00e7\u00e3o e figura da \u00e1rvore para ilustra\u00e7\u00e3o dos resultados.</p> </li> </ul>"},{"location":"K-mean/main/","title":"K-mean","text":"outputcode 2025-10-28T15:26:20.439294 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.cluster import KMeans\n\n# Usa o CSV como base (duas primeiras colunas num\u00e9ricas, para manter o mesmo plot)\ndf = pd.read_csv('https://raw.githubusercontent.com/marcelademartini/Machine-Learning-1/refs/heads/main/Testing.csv')\nX_num = df.select_dtypes(include=[np.number]).dropna()\n\nif X_num.shape[1] &gt;= 2:\n    X = X_num.iloc[:, :2].to_numpy()\nelse:\n    # Se s\u00f3 houver 1 coluna num\u00e9rica, duplica para conseguir plotar em 2D\n    col = X_num.iloc[:, 0].to_numpy().reshape(-1, 1)\n    X = np.hstack([col, col])\n\n\nplt.figure(figsize=(12, 10))\n\n\n# Run K-Means\nkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X)\n\n# Plot results\nplt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n           c='red', marker='*', s=200, label='Centroids')\nplt.title('K-Means Clustering Results')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\n\n# # Print centroids and inertia\n# print(\"Final centroids:\", kmeans.cluster_centers_)\n# print(\"Inertia (WCSS):\", kmeans.inertia_)\n\n# # Display the plot\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"K-mean/main/#1-exploracao-dos-dados","title":"1) Explora\u00e7\u00e3o dos dados","text":"<ul> <li>Leitura e natureza do conjunto: o script l\u00ea um CSV remoto para um <code>DataFrame</code> (<code>pd.read_csv(...)</code>). Em seguida, seleciona apenas as colunas num\u00e9ricas (<code>select_dtypes(include=[np.number])</code>) e remove linhas com valores ausentes nessas colunas (<code>dropna()</code>).</li> <li>Sele\u00e7\u00e3o de features para visualiza\u00e7\u00e3o: se houver duas ou mais colunas num\u00e9ricas, o c\u00f3digo pega as duas primeiras (<code>iloc[:, :2]</code>) e as converte para <code>numpy</code> para formar <code>X</code>. Se houver apenas uma coluna num\u00e9rica, ele duplica essa coluna para construir um plano 2D e permitir o gr\u00e1fico de dispers\u00e3o.</li> <li>Visualiza\u00e7\u00e3o: cria uma figura (<code>plt.figure(...)</code>) e, ap\u00f3s o agrupamento, plota um scatter dos pontos coloridos pelos r\u00f3tulos de cluster e marca os centr\u00f3ides com um asterisco vermelho.</li> <li>Estat\u00edsticas descritivas: n\u00e3o s\u00e3o calculadas no script (n\u00e3o h\u00e1 <code>describe()</code>, m\u00e9dias, desvios, histogramas etc.).</li> </ul>"},{"location":"K-mean/main/#2-pre-processamento","title":"2) Pr\u00e9-processamento","text":"<ul> <li>Tratamento de ausentes: o c\u00f3digo faz <code>dropna()</code> nas colunas num\u00e9ricas selecionadas, removendo linhas com NaN antes do modelo.</li> <li>Normaliza\u00e7\u00e3o/Escala: n\u00e3o h\u00e1 normaliza\u00e7\u00e3o/padroniza\u00e7\u00e3o; as features s\u00e3o usadas no escala original.</li> <li>Outros passos (remo\u00e7\u00e3o de outliers, codifica\u00e7\u00e3o categ\u00f3rica etc.): n\u00e3o s\u00e3o realizados.</li> </ul>"},{"location":"K-mean/main/#3-divisao-dos-dados-treino-e-teste","title":"3) Divis\u00e3o dos dados (treino e teste)","text":"<ul> <li>N\u00e3o ocorre divis\u00e3o. O script n\u00e3o cria conjuntos de treino e teste; todo o <code>X</code> \u00e9 utilizado diretamente no ajuste do algoritmo. (Isso \u00e9 coerente com o uso atual do script, que faz agrupamento n\u00e3o supervisionado.)</li> </ul>"},{"location":"K-mean/main/#4-treinamento-do-modelo","title":"4) Treinamento do modelo","text":"<ul> <li>Algoritmo implementado: o script treina K-Means com <code>n_clusters=3</code>, inicializa\u00e7\u00e3o <code>k-means++</code>, <code>max_iter=100</code> e <code>random_state=42</code>.</li> <li>Ajuste e r\u00f3tulos: <code>fit_predict(X)</code> executa o agrupamento sobre todas as observa\u00e7\u00f5es em <code>X</code> e retorna <code>labels</code>, que indicam a qual cluster (0, 1, 2) cada ponto pertence.</li> </ul>"},{"location":"K-mean/main/#5-avaliacao-do-modelo","title":"5) Avalia\u00e7\u00e3o do modelo","text":"<ul> <li>Avalia\u00e7\u00e3o visual: o gr\u00e1fico resultante mostra a distribui\u00e7\u00e3o dos pontos por cluster e a posi\u00e7\u00e3o dos centr\u00f3ides. Essa \u00e9 a base de avalia\u00e7\u00e3o presente no script.</li> <li>M\u00e9tricas num\u00e9ricas: h\u00e1 linhas comentadas para imprimir centr\u00f3ides e in\u00e9rcia (WCSS); como est\u00e3o comentadas, nenhuma m\u00e9trica \u00e9 exibida. N\u00e3o h\u00e1 c\u00e1lculo de outras m\u00e9tricas (ex.: silhouette).</li> </ul>"},{"location":"K-mean/main/#6-relatorio-final-processo-resultados-possiveis-melhorias","title":"6) Relat\u00f3rio final (processo, resultados, poss\u00edveis melhorias)","text":"<ul> <li> <p>Processo implementado:</p> </li> <li> <p>leitura do CSV e filtragem de colunas num\u00e9ricas;</p> </li> <li>remo\u00e7\u00e3o de ausentes;</li> <li>escolha de duas features (ou duplica\u00e7\u00e3o da \u00fanica feature) para visualiza\u00e7\u00e3o 2D;</li> <li>treinamento do K-Means (k=3);</li> <li>gera\u00e7\u00e3o de gr\u00e1fico de dispers\u00e3o com r\u00f3tulos e centr\u00f3ides;</li> <li>salvamento em SVG para buffer e impress\u00e3o do conte\u00fado SVG no stdout.</li> <li>Resultados gerados: um SVG contendo o gr\u00e1fico de clusters com tr\u00eas grupos e seus centr\u00f3ides.</li> <li>Aspectos n\u00e3o contemplados no script (apenas descri\u00e7\u00e3o): estat\u00edsticas descritivas, normaliza\u00e7\u00e3o, divis\u00e3o treino-teste, implementa\u00e7\u00e3o de KNN e m\u00e9tricas de desempenho supervisionadas n\u00e3o est\u00e3o presentes no c\u00f3digo.</li> </ul>"},{"location":"KNN/main/","title":"KNN","text":"output <p>              precision    recall  f1-score   support             0      0.783     0.837     0.809        43            1      0.562     0.474     0.514        19      accuracy                          0.726        62    macro avg      0.673     0.655     0.662        62 weighted avg      0.715     0.726     0.719        62   2025-10-28T15:26:20.703818 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ 2025-10-28T15:26:20.886384 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> code <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.decomposition import PCA\n\n# ===== 1) Carrega o CSV =====\ndf = pd.read_csv('https://raw.githubusercontent.com/marcelademartini/Machine-Learning-1/refs/heads/main/Testing.csv')\n\n# Define a coluna alvo \ntarget = 'Outcome' if 'Outcome' in df.columns else df.columns[-1]\n\n# X e y (dummies para categ\u00f3ricas)\nX_raw = df.drop(columns=[target])\nX = pd.get_dummies(X_raw, drop_first=True)\ny = df[target]\n\n# Codifica alvo n\u00e3o num\u00e9rico\nif not np.issubdtype(y.dtype, np.number):\n    y = pd.factorize(y)[0]\n\n# Trata NaN\nX = X.fillna(X.median(numeric_only=True))\n\n# ===== 2) Split + escala =====\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y if len(np.unique(y)) &gt; 1 else None\n)\n\nscaler = StandardScaler()\nX_train_s = scaler.fit_transform(X_train)\nX_test_s  = scaler.transform(X_test)\n\n# ===== 3) Treina KNN =====\nk = 3\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train_s, y_train)\ny_pred = knn.predict(X_test_s)\n\n# ===== 4) M\u00e9tricas =====\nacc = accuracy_score(y_test, y_pred)\nprint(classification_report(y_test, y_pred, digits=3))\n\n\n# ===== Helper: imprimir figura como SVG  =====\ndef print_svg_current_fig():\n    buf = StringIO()\n    plt.savefig(buf, format=\"svg\", transparent=True, bbox_inches=\"tight\")\n    print(buf.getvalue())\n    plt.close()\n\n# ===== 5) Matriz de confus\u00e3o  =====\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(5,4), dpi=120)\nplt.imshow(cm, interpolation='nearest')\nplt.title(\"Matriz de Confus\u00e3o (teste)\")\nplt.xlabel(\"Predito\")\nplt.ylabel(\"Real\")\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\nplt.colorbar()\nprint_svg_current_fig()\n\n# ===== 6) Visualiza\u00e7\u00e3o 2D (PCA) da fronteira de decis\u00e3o  =====\nif X_train.shape[1] &gt;= 2:\n    pca = PCA(n_components=2, random_state=42)\n    X_train_2d = pca.fit_transform(X_train_s)\n    X_test_2d  = pca.transform(X_test_s)\n\n    knn_viz = KNeighborsClassifier(n_neighbors=k).fit(X_train_2d, y_train)\n\n    h = 0.05\n    x_min, x_max = X_train_2d[:, 0].min() - 0.5, X_train_2d[:, 0].max() + 0.5\n    y_min, y_max = X_train_2d[:, 1].min() - 0.5, X_train_2d[:, 1].max() + 0.5\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Z = knn_viz.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\n    plt.figure(figsize=(6,5), dpi=120)\n    plt.contourf(xx, yy, Z, alpha=0.30)\n    plt.scatter(X_train_2d[:,0], X_train_2d[:,1], c=y_train, s=20, marker='o', label='treino')\n    plt.scatter(X_test_2d[:,0],  X_test_2d[:,1],  c=y_test,  s=40, marker='x', label='teste')\n    plt.title(f\"Fronteira de Decis\u00e3o (PCA 2D) \u2014 KNN k={k}\")\n    plt.xlabel(\"PC1\")\n    plt.ylabel(\"PC2\")\n    plt.legend(loc=\"best\")\n    print_svg_current_fig()\n</code></pre>"},{"location":"KNN/main/#1-exploracao-dos-dados","title":"1) Explora\u00e7\u00e3o dos Dados","text":"<ul> <li> <p>Leitura do conjunto de dados: o CSV \u00e9 carregado de uma URL do GitHub para o DataFrame df:</p> </li> <li> <p>df = pd.read_csv('https://raw.githubusercontent.com/.../Testing.csv').</p> </li> <li> <p>Natureza do problema (supervisionado): o c\u00f3digo define automaticamente a coluna-alvo para classifica\u00e7\u00e3o:</p> </li> <li> <p>target = 'Outcome' se essa coluna existir; caso contr\u00e1rio, usa a \u00faltima coluna do CSV (df.columns[-1]).</p> </li> <li> <p>Separa\u00e7\u00e3o inicial de vari\u00e1veis:</p> </li> <li> <p>X_raw = df.drop(columns=[target]) (preditoras).</p> </li> <li> <p>y = df[target] (alvo).</p> </li> <li> <p>Tipos de dados:</p> </li> <li> <p>Preditoras categ\u00f3ricas s\u00e3o transformadas em dummies com pd.get_dummies(..., drop_first=True), o que cria colunas bin\u00e1rias para categorias.</p> </li> <li> <p>Se o alvo n\u00e3o for num\u00e9rico, ele \u00e9 codificado em inteiros com pd.factorize.</p> </li> </ul>"},{"location":"KNN/main/#2-pre-processamento","title":"2) Pr\u00e9-processamento","text":"<ul> <li>Tratamento de ausentes (NaN):</li> </ul> <p>X = X.fillna(X.median(numeric_only=True)): preenche valores faltantes nas colunas num\u00e9ricas com a mediana de cada coluna.</p> <ul> <li>Codifica\u00e7\u00e3o de categ\u00f3ricas:</li> </ul> <p>pd.get_dummies(X_raw, drop_first=True): converte todas as colunas categ\u00f3ricas de X_raw para vari\u00e1veis indicadoras, descartando a primeira categoria (evita redund\u00e2ncia).</p> <ul> <li> <p>Padroniza\u00e7\u00e3o (normaliza\u00e7\u00e3o z-score):</p> </li> <li> <p>StandardScaler() \u00e9 ajustado em X_train e aplicado em X_train/X_test, produzindo X_train_s e X_test_s. Isso centraliza (m\u00e9dia 0) e escala (desvio 1) as features, o que \u00e9 importante para KNN.</p> </li> </ul>"},{"location":"KNN/main/#3-divisao-dos-dados","title":"3) Divis\u00e3o dos Dados","text":"<ul> <li> <p>Hold-out 80/20:</p> </li> <li> <p>train_test_split(..., test_size=0.2, random_state=42, stratify=...).</p> </li> <li> <p>Estratifica\u00e7\u00e3o:</p> </li> <li> <p>Se houver mais de uma classe no alvo, o split \u00e9 estratificado para manter as propor\u00e7\u00f5es de classes em treino e teste.</p> </li> <li> <p>Reprodutibilidade:</p> </li> <li> <p>random_state=42 garante que a mesma divis\u00e3o seja reproduz\u00edvel.</p> </li> </ul>"},{"location":"KNN/main/#4-treinamento-do-modelo-knn","title":"4) Treinamento do Modelo (KNN)","text":"<ul> <li> <p>Algoritmo: KNeighborsClassifier com n_neighbors=k, onde k = 3.</p> </li> <li> <p>Treinamento:</p> </li> <li> <p>knn.fit(X_train_s, y_train) usa as features padronizadas de treino.</p> </li> <li> <p>Predi\u00e7\u00e3o:</p> </li> <li> <p>y_pred = knn.predict(X_test_s) gera as classes previstas para o conjunto de teste.</p> </li> </ul>"},{"location":"KNN/main/#5-avaliacao-do-modelo","title":"5) Avalia\u00e7\u00e3o do Modelo","text":"<ul> <li> <p>M\u00e9tricas impressas:</p> </li> <li> <p>accuracy_score(y_test, y_pred) (acur\u00e1cia) \u00e9 calculada e armazenada em acc.</p> </li> <li> <p>classification_report(y_test, y_pred, digits=3) \u00e9 impresso no console com precision, recall, f1-score e support por classe, al\u00e9m das m\u00e9dias.</p> </li> <li> <p>Matriz de confus\u00e3o (figura):</p> </li> <li> <p>confusion_matrix(y_test, y_pred) gera a matriz cm.</p> </li> <li> <p>Em seguida, \u00e9 plotada com plt.imshow(cm, ...), adiciona-se plt.colorbar() e os n\u00fameros das c\u00e9lulas s\u00e3o sobrepostos com plt.text(...).</p> </li> <li> <p>A figura \u00e9 exportada como SVG por print_svg_current_fig(), que salva no buffer (StringIO) e imprime o SVG no stdout (\u00fatil para ambientes que capturam a sa\u00edda).</p> </li> </ul> <p>Visualiza\u00e7\u00e3o da fronteira de decis\u00e3o em 2D (PCA):</p> <ul> <li> <p>Se X_train tiver \u2265 2 features, aplica-se PCA para reduzir X_train_s/X_test_s a 2 componentes: X_train_2d, X_test_2d.</p> </li> <li> <p>Treina-se um KNN separado para visualiza\u00e7\u00e3o (knn_viz) neste espa\u00e7o 2D.</p> </li> <li> <p>Cria-se uma malha (np.meshgrid) e plota-se plt.contourf(...) com as regi\u00f5es de decis\u00e3o do KNN em 2D.</p> </li> <li> <p>Os pontos de treino (c\u00edrculos) e teste (xis) s\u00e3o sobrepostos, coloridos pelas classes verdadeiras.</p> </li> <li> <p>Esta figura tamb\u00e9m \u00e9 exportada como SVG via print_svg_current_fig().</p> </li> </ul>"},{"location":"KNN/main/#6-relatorio-final-documentacao-do-que-o-codigo-produz","title":"6) Relat\u00f3rio Final (documenta\u00e7\u00e3o do que o c\u00f3digo produz)","text":"<ul> <li> <p>Processo documentado pelo c\u00f3digo:</p> </li> <li> <p>Entrada: leitura do CSV remoto e defini\u00e7\u00e3o autom\u00e1tica do alvo.</p> </li> <li> <p>Pr\u00e9-processamento: dummies para categ\u00f3ricas, fatoriza\u00e7\u00e3o do alvo se necess\u00e1rio, imputa\u00e7\u00e3o por mediana para NaN e padroniza\u00e7\u00e3o via StandardScaler.</p> </li> <li> <p>Divis\u00e3o: treino/teste 80/20 com estratifica\u00e7\u00e3o quando aplic\u00e1vel.</p> </li> <li> <p>Modelo: KNN com k=3, treinado em dados padronizados.</p> </li> <li> <p>Sa\u00eddas:</p> </li> <li> <p>Texto: relat\u00f3rio de classifica\u00e7\u00e3o (precision, recall, f1, support) e a acur\u00e1cia (em acc).</p> </li> <li> <p>Figuras (SVG, impressas no stdout):</p> </li> <li> <p>Matriz de confus\u00e3o do conjunto de teste.</p> </li> <li> <p>Fronteira de decis\u00e3o em 2D ap\u00f3s redu\u00e7\u00e3o por PCA, com pontos de treino e teste.</p> </li> <li> <p>Resultados obtidos:</p> </li> <li> <p>O console exibir\u00e1 o classification_report com m\u00e9tricas por classe e m\u00e9dias; a acur\u00e1cia est\u00e1 dispon\u00edvel na vari\u00e1vel acc.</p> </li> <li> <p>Duas figuras SVG s\u00e3o geradas na sa\u00edda: (i) Matriz de confus\u00e3o e (ii) Fronteira de decis\u00e3o (PCA 2D).</p> </li> </ul> <p>*Poss\u00edveis melhorias (nota descritiva): n\u00e3o fazem parte do c\u00f3digo atual; portanto, o relat\u00f3rio final se limita \u00e0s etapas e produtos acima executados pelo script.</p>"},{"location":"Metrics/main/","title":"Metrics","text":"output <p>              precision    recall  f1-score   support             0      0.783     0.837     0.809        43            1      0.562     0.474     0.514        19      accuracy                          0.726        62    macro avg      0.673     0.655     0.662        62 weighted avg      0.715     0.726     0.719        62   2025-10-28T15:26:21.236780 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ 2025-10-28T15:26:21.409334 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> code <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.decomposition import PCA\n\n# ===== 1) Carrega o CSV =====\ndf = pd.read_csv('https://raw.githubusercontent.com/marcelademartini/Machine-Learning-1/refs/heads/main/Testing.csv')\n\n# Define a coluna alvo \ntarget = 'Outcome' if 'Outcome' in df.columns else df.columns[-1]\n\n# X e y (dummies para categ\u00f3ricas)\nX_raw = df.drop(columns=[target])\nX = pd.get_dummies(X_raw, drop_first=True)\ny = df[target]\n\n# Codifica alvo n\u00e3o num\u00e9rico\nif not np.issubdtype(y.dtype, np.number):\n    y = pd.factorize(y)[0]\n\n# Trata NaN\nX = X.fillna(X.median(numeric_only=True))\n\n# ===== 2) Split + escala =====\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y if len(np.unique(y)) &gt; 1 else None\n)\n\nscaler = StandardScaler()\nX_train_s = scaler.fit_transform(X_train)\nX_test_s  = scaler.transform(X_test)\n\n# ===== 3) Treina KNN =====\nk = 3\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train_s, y_train)\ny_pred = knn.predict(X_test_s)\n\n# ===== 4) M\u00e9tricas =====\nacc = accuracy_score(y_test, y_pred)\nprint(classification_report(y_test, y_pred, digits=3))\n\n\n# ===== Helper: imprimir figura como SVG  =====\ndef print_svg_current_fig():\n    buf = StringIO()\n    plt.savefig(buf, format=\"svg\", transparent=True, bbox_inches=\"tight\")\n    print(buf.getvalue())\n    plt.close()\n\n# ===== 5) Matriz de confus\u00e3o  =====\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(5,4), dpi=120)\nplt.imshow(cm, interpolation='nearest')\nplt.title(\"Matriz de Confus\u00e3o (teste)\")\nplt.xlabel(\"Predito\")\nplt.ylabel(\"Real\")\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\nplt.colorbar()\nprint_svg_current_fig()\n\n# ===== 6) Visualiza\u00e7\u00e3o 2D (PCA) da fronteira de decis\u00e3o  =====\nif X_train.shape[1] &gt;= 2:\n    pca = PCA(n_components=2, random_state=42)\n    X_train_2d = pca.fit_transform(X_train_s)\n    X_test_2d  = pca.transform(X_test_s)\n\n    knn_viz = KNeighborsClassifier(n_neighbors=k).fit(X_train_2d, y_train)\n\n    h = 0.05\n    x_min, x_max = X_train_2d[:, 0].min() - 0.5, X_train_2d[:, 0].max() + 0.5\n    y_min, y_max = X_train_2d[:, 1].min() - 0.5, X_train_2d[:, 1].max() + 0.5\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    Z = knn_viz.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\n    plt.figure(figsize=(6,5), dpi=120)\n    plt.contourf(xx, yy, Z, alpha=0.30)\n    plt.scatter(X_train_2d[:,0], X_train_2d[:,1], c=y_train, s=20, marker='o', label='treino')\n    plt.scatter(X_test_2d[:,0],  X_test_2d[:,1],  c=y_test,  s=40, marker='x', label='teste')\n    plt.title(f\"Fronteira de Decis\u00e3o (PCA 2D) \u2014 KNN k={k}\")\n    plt.xlabel(\"PC1\")\n    plt.ylabel(\"PC2\")\n    plt.legend(loc=\"best\")\n    print_svg_current_fig()\n</code></pre> output <p>Matriz de Confus\u00e3o (bruta) \u2014 y_true x cluster:  [[111  17  87]  [ 11  39  43]  [  0   0   0]]  2025-10-28T15:26:21.642177 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/    Matriz de Confus\u00e3o (clusters remapeados \u2192 classes):  [[198  17]  [ 54  39]] Melhor permuta\u00e7\u00e3o cluster-&gt;classe encontrada: {0: np.int64(0), 1: np.int64(1)}  2025-10-28T15:26:21.825986 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ 2025-10-28T15:26:21.987187 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> code <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom itertools import permutations\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import confusion_matrix\n\n# ===== Helper: imprimir figura como SVG =====\ndef print_svg_current_fig():\n    buf = StringIO()\n    plt.savefig(buf, format=\"svg\", transparent=True, bbox_inches=\"tight\")\n    print(buf.getvalue())\n    plt.close()\n\n# ===== 1) Carrega o CSV =====\ndf = pd.read_csv('https://raw.githubusercontent.com/marcelademartini/Machine-Learning-1/refs/heads/main/Testing.csv')\n\n# Garante alvo verdadeiro (para comparar com clusters)\nif 'Outcome' not in df.columns:\n    raise ValueError(\"N\u00e3o h\u00e1 coluna 'Outcome' no CSV \u2014 sem r\u00f3tulos reais n\u00e3o d\u00e1 para fazer matriz de confus\u00e3o.\")\n\ny_true = df['Outcome'].to_numpy()\n\n# ===== 2) Seleciona features num\u00e9ricas =====\nX_num = df.select_dtypes(include=[np.number]).dropna()\n\nif X_num.shape[1] &gt;= 2:\n    X = X_num.iloc[:, :2].to_numpy()\nelse:\n    col = X_num.iloc[:, 0].to_numpy().reshape(-1, 1)\n    X = np.hstack([col, col])\n\n# ===== 3) Roda K-Means =====\nk = 3\nkmeans = KMeans(n_clusters=k, init='k-means++', max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X)\n\n# ===== 4) MATRIZ DE CONFUS\u00c3O (BRUTA): classes reais x clusters =====\ncm_raw = confusion_matrix(y_true, labels)\nprint(\"Matriz de Confus\u00e3o (bruta) \u2014 y_true x cluster:\\n\", cm_raw)\n\nplt.figure(figsize=(5,4), dpi=120)\nplt.imshow(cm_raw, interpolation='nearest')\nplt.title(\"Matriz de Confus\u00e3o (bruta)\\n(Classes reais \u00d7 Clusters)\")\nplt.xlabel(\"Cluster (predito pelo K-Means)\")\nplt.ylabel(\"Classe real (Outcome)\")\nfor i in range(cm_raw.shape[0]):\n    for j in range(cm_raw.shape[1]):\n        plt.text(j, i, str(cm_raw[i, j]), ha=\"center\", va=\"center\")\nplt.colorbar()\nprint_svg_current_fig()\n\n# ===== 5)REMAPEAMENTO DOS CLUSTERS PARA CLASSES =====\n# Tenta encontrar a melhor permuta\u00e7\u00e3o de mapeamento cluster-&gt;classe que maximize acertos\nclasses = np.unique(y_true)\nn_classes = len(classes)\nn_clusters = k\n\n# Se n\u00famero de clusters &gt;= n\u00famero de classes\nbest_perm = None\nbest_hits = -1\n\nfor perm in permutations(range(n_clusters), n_classes):\n    # constr\u00f3i predi\u00e7\u00e3o remapeando apenas os clusters usados (demais ficam como a primeira classe)\n    map_dict = {cluster_idx: classes[i] for i, cluster_idx in enumerate(perm)}\n    y_mapped = np.array([map_dict.get(c, classes[0]) for c in labels])\n    hits = (y_mapped == y_true).sum()\n    if hits &gt; best_hits:\n        best_hits = hits\n        best_perm = perm\n\n# Aplica melhor mapeamento encontrado\nmap_dict = {cluster_idx: classes[i] for i, cluster_idx in enumerate(best_perm)}\ny_pred_mapped = np.array([map_dict.get(c, classes[0]) for c in labels])\n\ncm_mapped = confusion_matrix(y_true, y_pred_mapped)\nprint(\"\\nMatriz de Confus\u00e3o (clusters remapeados \u2192 classes):\\n\", cm_mapped)\nprint(\"Melhor permuta\u00e7\u00e3o cluster-&gt;classe encontrada:\", map_dict)\n\nplt.figure(figsize=(5,4), dpi=120)\nplt.imshow(cm_mapped, interpolation='nearest')\nplt.title(\"Matriz de Confus\u00e3o (clusters remapeados)\")\nplt.xlabel(\"Predito (ap\u00f3s remapeamento)\")\nplt.ylabel(\"Classe real (Outcome)\")\nfor i in range(cm_mapped.shape[0]):\n    for j in range(cm_mapped.shape[1]):\n        plt.text(j, i, str(cm_mapped[i, j]), ha=\"center\", va=\"center\")\nplt.colorbar()\nprint_svg_current_fig()\n\n# ===== 6) Plot do clustering em 2D =====\nplt.figure(figsize=(6,5), dpi=120)\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=40, alpha=0.8, label='pontos', cmap='viridis')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c='red', marker='*', s=200, label='centroides')\nplt.title('K-Means Clustering Results')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend(loc='best')\nprint_svg_current_fig()\n</code></pre>"},{"location":"Metrics/main/#1-knn-passo-a-passo-do-meu-codigo","title":"1) KNN: passo a passo do meu c\u00f3digo","text":""},{"location":"Metrics/main/#11-importacao-e-leitura-do-csv","title":"1.1. Importa\u00e7\u00e3o e leitura do CSV","text":"<ul> <li> <p>Eu importo as bibliotecas do Python que preciso e leio o arquivo Testing.csv. Se existir a coluna Outcome, uso como alvo. Caso contr\u00e1rio, pego a \u00faltima coluna como alvo.</p> </li> <li> <p>Por que isso? Eu preciso de uma vari\u00e1vel de sa\u00edda para transformar o problema em classifica\u00e7\u00e3o supervisionada.</p> </li> </ul>"},{"location":"Metrics/main/#12-selecao-de-variaveis-e-tratamento-de-tipos","title":"1.2. Sele\u00e7\u00e3o de vari\u00e1veis e tratamento de tipos","text":"<ul> <li> <p>Eu separo X (todas as colunas menos o alvo) e y (o alvo). Se houver colunas categ\u00f3ricas em X, transformo em dummies com get_dummies. Se y n\u00e3o for num\u00e9rica, fatorizo para virar n\u00fameros inteiros.</p> </li> <li> <p>Por que isso? Modelos como KNN trabalham com n\u00fameros. Ent\u00e3o eu deixo tudo num\u00e9rico e consistente.</p> </li> </ul>"},{"location":"Metrics/main/#13-tratamento-de-ausentes","title":"1.3. Tratamento de ausentes","text":"<ul> <li> <p>Eu preencho valores ausentes em X com a mediana das colunas num\u00e9ricas.</p> </li> <li> <p>Por que isso? Evito perder linhas e mantenho a escala robusta a outliers.</p> </li> </ul>"},{"location":"Metrics/main/#14-split-treino-e-teste-com-estratificacao","title":"1.4. Split treino e teste com estratifica\u00e7\u00e3o","text":"<ul> <li> <p>Eu divido os dados em treino e teste usando train_test_split com test_size=0.2 e random_state=42. Se houver mais de uma classe, uso stratify=y para manter as propor\u00e7\u00f5es das classes nos dois conjuntos.</p> </li> <li> <p>Por que isso? Preciso medir desempenho em dados que o modelo n\u00e3o viu. A estratifica\u00e7\u00e3o evita desbalancear as classes no split.</p> </li> </ul>"},{"location":"Metrics/main/#15-padronizacao","title":"1.5. Padroniza\u00e7\u00e3o","text":"<ul> <li> <p>Eu padronizo X_train e X_test com StandardScaler (m\u00e9dia 0 e desvio 1).</p> </li> <li> <p>Por que isso? KNN usa dist\u00e2ncias. Se as escalas forem diferentes, uma vari\u00e1vel pode dominar a dist\u00e2ncia. Padronizar deixa tudo compar\u00e1vel.</p> </li> </ul>"},{"location":"Metrics/main/#16-treino-do-knn","title":"1.6. Treino do KNN","text":"<ul> <li> <p>Eu escolho k = 3, crio KNeighborsClassifier(n_neighbors=3), ajusto com fit e gero previs\u00f5es no teste com predict.</p> </li> <li> <p>Por que isso? KNN classifica um ponto olhando os vizinhos mais pr\u00f3ximos. k=3 \u00e9 um come\u00e7o simples para experimentar.</p> </li> </ul>"},{"location":"Metrics/main/#17-metricas-e-relatorio","title":"1.7. M\u00e9tricas e relat\u00f3rio","text":"<ul> <li> <p>Eu calculo a acur\u00e1cia e imprimo classification_report, que traz precis\u00e3o, recall e F1 por classe, al\u00e9m das m\u00e9dias.</p> </li> <li> <p>Como ler?</p> </li> <li> <p>Precis\u00e3o: dos positivos que eu previ, quantos eram realmente positivos</p> </li> <li> <p>Recall: dos positivos reais, quantos eu acertei</p> </li> <li> <p>F1: balan\u00e7o entre precis\u00e3o e recall</p> </li> </ul>"},{"location":"Metrics/main/#18-matriz-de-confusao-com-figura-em-svg","title":"1.8. Matriz de confus\u00e3o com figura em SVG","text":"<ul> <li> <p>Eu calculo cm = confusion_matrix(y_test, y_pred), ploto com imshow, escrevo os n\u00fameros em cada c\u00e9lula e exporto a figura como SVG usando a fun\u00e7\u00e3o print_svg_current_fig().</p> </li> <li> <p>Por que isso? A matriz de confus\u00e3o mostra onde o modelo acerta e onde se confunde entre as classes. Exportar em SVG mant\u00e9m a imagem n\u00edtida no navegador e no GitPages.</p> </li> </ul>"},{"location":"Metrics/main/#19-visualizacao-2d-com-pca-e-fronteira-de-decisao","title":"1.9. Visualiza\u00e7\u00e3o 2D com PCA e fronteira de decis\u00e3o","text":"<ul> <li> <p>Se houver pelo menos duas features, eu rodo um PCA para reduzir para 2 componentes e treino um KNN nesse espa\u00e7o 2D apenas para visualiza\u00e7\u00e3o. Depois eu desenho a fronteira de decis\u00e3o com contourf, marco os pontos de treino e teste, e exporto em SVG.</p> </li> <li> <p>Por que isso? Ver a fronteira de decis\u00e3o ajuda a entender como o KNN est\u00e1 separando as classes depois da redu\u00e7\u00e3o de dimensionalidade. \u00c9 apenas ilustrativo.</p> </li> </ul>"},{"location":"Metrics/main/#2-k-means-matriz-de-confusao-usando-a-mesma-logica-visual","title":"2) K-Means: matriz de confus\u00e3o usando a mesma l\u00f3gica visual","text":"<ul> <li>O K-Means \u00e9 n\u00e3o supervisionado, ent\u00e3o ele cria clusters sem saber a classe real. Mesmo assim, se o meu dataset tem uma coluna alvo (por exemplo, Outcome), eu posso comparar os clusters com essa coluna para inspecionar o alinhamento entre grupos encontrados e as classes reais.</li> </ul>"},{"location":"Metrics/main/#21-o-que-eu-faco-antes-de-treinar","title":"2.1. O que eu fa\u00e7o antes de treinar","text":"<ul> <li> <p>Carrego o Testing.csv</p> </li> <li> <p>Confirmo que Outcome existe para poder comparar</p> </li> <li> <p>Seleciono apenas colunas num\u00e9ricas</p> </li> <li> <p>Para visualiza\u00e7\u00e3o, uso as duas primeiras colunas num\u00e9ricas. Se s\u00f3 tiver uma, eu duplico para formar um plano 2D</p> </li> </ul>"},{"location":"Metrics/main/#22-treino-do-k-means","title":"2.2. Treino do K-Means","text":"<ul> <li> <p>Eu rodo KMeans(n_clusters=3, init='k-means++', max_iter=100, random_state=42) e pego os r\u00f3tulos de cluster com fit_predict.</p> </li> <li> <p>Por que 3 clusters? \u00c9 um valor inicial para observar o comportamento. Posso variar para testar.</p> </li> </ul>"},{"location":"Metrics/main/#23-matriz-de-confusao-bruta-classes-reais-clusters","title":"2.3. Matriz de confus\u00e3o bruta: classes reais \u00d7 clusters","text":"<ul> <li> <p>Eu calculo cm_raw = confusion_matrix(y_true, labels) e ploto do mesmo jeito que no KNN: imshow, n\u00fameros nas c\u00e9lulas e exporta\u00e7\u00e3o SVG pela mesma fun\u00e7\u00e3o.</p> </li> <li> <p>Importante: esta matriz \u00e9 bruta. Cluster 0 n\u00e3o quer dizer classe 0, porque os r\u00f3tulos de cluster s\u00e3o arbitr\u00e1rios.</p> </li> </ul>"},{"location":"Metrics/main/#24-remapeamento-de-clusters-para-classes","title":"2.4. Remapeamento de clusters para classes","text":"<ul> <li> <p>Para tornar a leitura mais parecida com classifica\u00e7\u00e3o, eu tento mapear os clusters para as classes reais. Eu testo todas as permuta\u00e7\u00f5es poss\u00edveis de cluster para classe e escolho a que d\u00e1 mais acertos. Com esse mapeamento, eu gero uma segunda matriz de confus\u00e3o, agora \u201calinhada\u201d.</p> </li> <li> <p>Por que isso ajuda? Ajuda a ler a matriz como se fosse uma predi\u00e7\u00e3o de classe. Ainda \u00e9 um modelo n\u00e3o supervisionado, mas o remapeamento torna a compara\u00e7\u00e3o mais clara.</p> </li> </ul>"},{"location":"Metrics/main/#25-visualizacao-2d-dos-clusters","title":"2.5. Visualiza\u00e7\u00e3o 2D dos clusters","text":"<ul> <li> <p>Eu desenho um scatter plot dos pontos coloridos pelos r\u00f3tulos de cluster e marco os centr\u00f3ides com estrelas. Exporto em SVG.</p> </li> <li> <p>Por que isso? Ver a distribui\u00e7\u00e3o no plano 2D ajuda a entender como os clusters ficaram.</p> </li> </ul>"},{"location":"Metrics/main/#3-observacoes-e-limitacoes","title":"3) Observa\u00e7\u00f5es e limita\u00e7\u00f5es","text":"<ul> <li> <p>No KNN, a matriz de confus\u00e3o \u00e9 direta porque existem classes reais e previs\u00f5es.</p> </li> <li> <p>No K-Means, a matriz de confus\u00e3o precisa ser interpretada com cuidado, porque os r\u00f3tulos de cluster s\u00e3o arbitr\u00e1rios. O remapeamento \u00e9 uma etapa extra que melhora a compara\u00e7\u00e3o, mas n\u00e3o transforma o K-Means em um classificador supervisionado.</p> </li> <li> <p>Padronizar dados \u00e9 essencial para KNN e geralmente ajuda bastante em m\u00e9todos baseados em dist\u00e2ncia.</p> </li> <li> <p>No K-Means, escolher o n\u00famero de clusters \u00e9 uma decis\u00e3o importante. Vale testar valores diferentes e usar m\u00e9tricas de clusteriza\u00e7\u00e3o como silhouette e Davies Bouldin.</p> </li> </ul>"},{"location":"Metrics/main/#4-como-reproduzir","title":"4) Como reproduzir","text":"<ul> <li> <p>Coloque Testing.csv na mesma pasta dos notebooks ou scripts.</p> </li> <li> <p>Para o KNN, rode o script principal. Ele j\u00e1:</p> </li> <li> <p>prepara dados</p> </li> <li> <p>treina o modelo</p> </li> <li> <p>imprime relat\u00f3rio de classifica\u00e7\u00e3o</p> </li> <li> <p>gera e imprime a matriz de confus\u00e3o</p> </li> <li> <p>exporta as figuras como SVG</p> </li> <li> <p>Para o K-Means, rode o script de clustering. Ele:</p> </li> <li> <p>gera a matriz de confus\u00e3o bruta</p> </li> <li> <p>remapeia clusters para classes e gera a matriz alinhada</p> </li> <li> <p>cria o scatter com centr\u00f3ides</p> </li> <li> <p>exporta tudo como SVG</p> </li> <li> <p>Se eu quiser publicar no GitPages, os SVGs ficam n\u00edtidos e leves, ent\u00e3o as figuras carregam r\u00e1pido e com boa qualidade.</p> </li> </ul>"},{"location":"Metrics/main/#5-ideias-de-extensao","title":"5) Ideias de extens\u00e3o","text":"<ul> <li> <p>Ajustar k no KNN e comparar as m\u00e9tricas</p> </li> <li> <p>Usar valida\u00e7\u00e3o cruzada para avaliar estabilidade</p> </li> <li> <p>Testar diferentes n\u00fameros de clusters e calcular silhouette</p> </li> <li> <p>Usar mais componentes no PCA e s\u00f3 reduzir para 2D na hora da visualiza\u00e7\u00e3o</p> </li> <li> <p>Comparar K-Means com outros m\u00e9todos de clusteriza\u00e7\u00e3o como DBSCAN e GMM</p> </li> </ul>"},{"location":"Metrics/main/#comparacao-entre-knn-e-k-means","title":"Compara\u00e7\u00e3o entre KNN e K-Means","text":""},{"location":"Metrics/main/#1-resultados-do-knn","title":"1) Resultados do KNN","text":"<ul> <li>Matriz de confus\u00e3o </li> <li>36 verdadeiros negativos  </li> <li>7 falsos positivos  </li> <li>10 falsos negativos  </li> <li> <p>9 verdadeiros positivos  </p> </li> <li> <p>Fronteira de decis\u00e3o (PCA 2D) </p> </li> <li>As regi\u00f5es de decis\u00e3o mostram bastante sobreposi\u00e7\u00e3o.  </li> <li>Isso explica a acur\u00e1cia de aproximadamente 72%.  </li> <li>O modelo acerta mais a classe 0, mas erra bastante na classe 1.  </li> </ul>"},{"location":"Metrics/main/#2-resultados-do-k-means","title":"2) Resultados do K-Means","text":"<ul> <li>Matriz de confus\u00e3o bruta </li> <li>Clusters n\u00e3o correspondem diretamente \u00e0s classes.  </li> <li> <p>H\u00e1 mistura significativa entre classe 0 e 1.  </p> </li> <li> <p>Matriz de confus\u00e3o remapeada </p> </li> <li> <p>O alinhamento melhora os resultados, mas ainda h\u00e1 muitos falsos negativos (classe 1 confundida).  </p> </li> <li> <p>Visualiza\u00e7\u00e3o dos clusters </p> </li> <li>Centr\u00f4ides bem definidos.  </li> <li>Por\u00e9m, classes diferentes caem nos mesmos clusters.  </li> </ul>"},{"location":"Metrics/main/#3-comparacao-final","title":"3) Compara\u00e7\u00e3o Final","text":"<ul> <li>KNN</li> <li>Supervisionado (usa r\u00f3tulos).  </li> <li>Acur\u00e1cia \u2248 72%.  </li> <li> <p>Generaliza melhor e distingue padr\u00f5es conhecidos.  </p> </li> <li> <p>K-Means</p> </li> <li>N\u00e3o supervisionado (n\u00e3o usa r\u00f3tulos).  </li> <li>Clusters n\u00e3o refletem perfeitamente as classes reais.  </li> <li>Mesmo remapeado, tem desempenho inferior.  </li> </ul>"},{"location":"Metrics/main/#4-conclusao","title":"4) Conclus\u00e3o","text":"<ul> <li>O KNN \u00e9 o melhor modelo para este dataset.  </li> <li>O K-Means \u00e9 \u00fatil para explorar agrupamentos, mas n\u00e3o substitui um classificador supervisionado quando os r\u00f3tulos est\u00e3o dispon\u00edveis.  </li> </ul>"},{"location":"pagerank/main/","title":"pagerank","text":""},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"pyspark/main/","title":"pyspark","text":"output code"},{"location":"randomforest/main/","title":"randomforest","text":"output <p>Acur\u00e1cia de valida\u00e7\u00e3o: 0.774 Acur\u00e1cia: 0.7741935483870968  Relat\u00f3rio de Classifica\u00e7\u00e3o (HTML):  precision recall f1-score support 0 0.900000 0.782609 0.837209 46.000000 1 0.545455 0.750000 0.631579 16.000000 accuracy 0.774194 0.774194 0.774194 0.774194 macro avg 0.722727 0.766304 0.734394 62.000000 weighted avg 0.808504 0.774194 0.784143 62.000000   Matriz de Confus\u00e3o (HTML):  0 1 0 36 10 1 4 12   Feature importances (sklearn RandomForestClassifier):  importance Glucose 0.274162 BMI 0.148344 Age 0.147295 DiabetesPedigreeFunction 0.111873 Pregnancies 0.108625 BloodPressure 0.085424 SkinThickness 0.065643 Insulin 0.058635 </p> code <pre><code>import os\nimport io\nimport math\nimport random\nimport requests\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\n\n# ===== 1) Ler o CSV (robusto) =====\nURL = \"https://raw.githubusercontent.com/marcelademartini/Machine-Learning-1/main/Testing.csv\"\nLOCAL_CANDIDATES = [\n    \"Testing.csv\",\n    os.path.join(\"docs\", \"randomforest\", \"Testing.csv\"),\n    os.path.join(\"docs\", \"Testing.csv\"),\n]\n\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef fetch_csv_with_retries(url, local_candidates=None, retries=3, timeout=10):\n    session = requests.Session()\n    retry = Retry(total=retries, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n    session.mount(\"https://\", HTTPAdapter(max_retries=retry))\n    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n    try:\n        resp = session.get(url, headers=headers, timeout=timeout)\n        resp.raise_for_status()\n        return pd.read_csv(io.StringIO(resp.text))\n    except Exception as e:\n        # try local candidates\n        if local_candidates:\n            for p in local_candidates:\n                if os.path.exists(p):\n                    return pd.read_csv(p)\n        raise RuntimeError(\n            f\"Failed to load CSV from URL '{url}' ({e}) and no local fallback found. \"\n            \"Place 'Testing.csv' in the repository (repo root or docs/randomforest/) or try again later.\"\n        )\n\n\ndf = fetch_csv_with_retries(URL, local_candidates=LOCAL_CANDIDATES)\n\n\n# ===== 2) Implementa\u00e7\u00e3o do RandomForest =====\ndef gini_impurity(y):\n    if not y:\n        return 0.0\n    counts = Counter(y)\n    impurity = 1.0\n    n = len(y)\n    for count in counts.values():\n        p = count / n\n        impurity -= p * p\n    return impurity\n\n\ndef split_dataset(X, y, feature_idx, value):\n    left_X, left_y, right_X, right_y = [], [], [], []\n    for xi, yi in zip(X, y):\n        if xi[feature_idx] &lt;= value:\n            left_X.append(xi)\n            left_y.append(yi)\n        else:\n            right_X.append(xi)\n            right_y.append(yi)\n    return left_X, left_y, right_X, right_y\n\n\nclass Node:\n    def __init__(self, feature_idx=None, value=None, left=None, right=None, label=None):\n        self.feature_idx = feature_idx\n        self.value = value\n        self.left = left\n        self.right = right\n        self.label = label\n\n\ndef build_tree(X, y, max_depth, min_samples_split, max_features):\n    # leaf\n    if len(y) &lt; min_samples_split or max_depth == 0:\n        return Node(label=Counter(y).most_common(1)[0][0])\n\n    n_features = len(X[0])\n    features = random.sample(range(n_features), min(max_features, n_features))\n\n    best_gini = float(\"inf\")\n    best = None\n\n    for fi in features:\n        values = sorted(set(row[fi] for row in X))\n        for v in values:\n            left_X, left_y, right_X, right_y = split_dataset(X, y, fi, v)\n            if not left_y or not right_y:\n                continue\n            p_left = len(left_y) / len(y)\n            g = p_left * gini_impurity(left_y) + (1 - p_left) * gini_impurity(right_y)\n            if g &lt; best_gini:\n                best_gini = g\n                best = (fi, v, left_X, left_y, right_X, right_y)\n\n    if best is None:\n        return Node(label=Counter(y).most_common(1)[0][0])\n\n    fi, v, lX, ly, rX, ry = best\n    left = build_tree(lX, ly, max_depth - 1, min_samples_split, max_features)\n    right = build_tree(rX, ry, max_depth - 1, min_samples_split, max_features)\n    return Node(feature_idx=fi, value=v, left=left, right=right)\n\n\ndef predict_tree(node, x):\n    if node.label is not None:\n        return node.label\n    if x[node.feature_idx] &lt;= node.value:\n        return predict_tree(node.left, x)\n    return predict_tree(node.right, x)\n\n\nclass RandomForest:\n    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, max_features='sqrt'):\n        self.n_estimators = n_estimators\n        self.max_depth = max_depth\n        self.min_samples_split = min_samples_split\n        self.max_features = max_features\n        self.trees = []\n\n    def fit(self, X, y):\n        self.trees = []\n        n_samples = len(X)\n        n_features = len(X[0])\n        if self.max_features == 'sqrt':\n            mf = max(1, int(math.sqrt(n_features)))\n        elif isinstance(self.max_features, int):\n            mf = min(self.max_features, n_features)\n        else:\n            mf = n_features\n\n        for _ in range(self.n_estimators):\n            idxs = [random.randint(0, n_samples - 1) for _ in range(n_samples)]\n            Xb = [X[i] for i in idxs]\n            yb = [y[i] for i in idxs]\n            tree = build_tree(Xb, yb, self.max_depth, self.min_samples_split, mf)\n            self.trees.append(tree)\n\n    def predict(self, X):\n        preds = []\n        for x in X:\n            votes = [predict_tree(t, x) for t in self.trees]\n            preds.append(Counter(votes).most_common(1)[0][0])\n        return preds\n\n\n# ===== 3) Preparar dados, treinar e avaliar =====\ntarget_col = \"Outcome\"\nif target_col not in df.columns:\n    raise RuntimeError(f\"Target column '{target_col}' not found in dataframe.\")\n\nfeature_cols = [c for c in df.columns if c != target_col]\n\n# converter para num\u00e9rico quando poss\u00edvel e preencher NaNs\nX_df = df[feature_cols].apply(pd.to_numeric, errors='coerce')\nX_df = X_df.fillna(X_df.median(numeric_only=True))\ny_series = df[target_col]\n# if y not numeric, encode to integers\nif not pd.api.types.is_integer_dtype(y_series) and not pd.api.types.is_bool_dtype(y_series):\n    y_series = pd.Categorical(y_series).codes\n\nX = X_df.values.tolist()\ny = y_series.tolist()\n\nn = len(X)\nrandom.seed(42)\nidx = list(range(n))\nrandom.shuffle(idx)\nsplit_idx = math.floor(n * 0.8)\ntrain_idx, val_idx = idx[:split_idx], idx[split_idx:]\n\nX_train = [X[i] for i in train_idx]\ny_train = [y[i] for i in train_idx]\nX_val = [X[i] for i in val_idx]\ny_val = [y[i] for i in val_idx]\n\n# train custom RF\nrf = RandomForest(n_estimators=15, max_depth=6, min_samples_split=4, max_features='sqrt')\nrf.fit(X_train, y_train)\npreds = rf.predict(X_val)\n\nacc = sum(int(p == t) for p, t in zip(preds, y_val)) / len(y_val)\nprint(f\"Acur\u00e1cia de valida\u00e7\u00e3o: {acc:.3f}\")\n\n# evaluate\nX_test = X_val\ny_test = y_val\n\ny_pred = rf.predict(X_test)\nprint(\"Acur\u00e1cia:\", accuracy_score(y_test, y_pred))\n\nreport_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T\nprint(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o (HTML):\")\nprint(report_df.to_html(classes=\"table table-sm\", border=0, index=True))\n\nlabels = sorted(list(set(y_test)))\ncm = confusion_matrix(y_test, y_pred, labels=labels)\ncm_df = pd.DataFrame(cm, index=labels, columns=labels)\nprint(\"\\nMatriz de Confus\u00e3o (HTML):\")\nprint(cm_df.to_html(classes=\"table table-sm\", border=0))\n\n# ===== Feature importances usando sklearn =====\ntry:\n    X_train_arr = np.array(X_train)\n    y_train_arr = np.array(y_train)\n    skrf = RandomForestClassifier(n_estimators=100, random_state=42)\n    skrf.fit(X_train_arr, y_train_arr)\n    imp = pd.Series(skrf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n    print(\"\\nFeature importances (sklearn RandomForestClassifier):\")\n    print(imp.to_frame(name=\"importance\").to_html(border=0))\nexcept Exception as e:\n    print(\"\\nCould not compute sklearn feature importances:\", e)\n</code></pre>"},{"location":"randomforest/main/#random-forest-classificacao-de-diabetes","title":"Random Forest \u2013 Classifica\u00e7\u00e3o de Diabetes","text":""},{"location":"randomforest/main/#1-exploracao-dos-dados","title":"1) Explora\u00e7\u00e3o dos Dados","text":"<ul> <li>Fonte: <code>Testing.csv</code> (dados cl\u00ednicos de pacientes).</li> <li>Alvo: <code>Outcome</code> (0 = sem diabetes, 1 = com diabetes).</li> <li>Atributos t\u00edpicos: Glucose, BloodPressure, BMI, Age, Pregnancies, SkinThickness, Insulin, DiabetesPedigreeFunction.</li> <li>Natureza: vari\u00e1veis num\u00e9ricas cont\u00ednuas; cada linha = um paciente.</li> </ul> <p>Observa\u00e7\u00e3o: \u00e9 um conjunto na linha do Pima Indians Diabetes, usado amplamente em tarefas de classifica\u00e7\u00e3o bin\u00e1ria.</p>"},{"location":"randomforest/main/#2-pre-processamento","title":"2) Pr\u00e9-processamento","text":"<ul> <li>Leitura robusta: tentativa por URL com retries; se falhar, busca arquivos locais candidatos.</li> <li>Convers\u00e3o: <code>pd.to_numeric(errors=\"coerce\")</code> em todas as features.</li> <li>Valores ausentes: preenchimento pela mediana por coluna.</li> <li>Alvo: garantido como inteiro/categ\u00f3rico codificado.</li> <li>Reprodutibilidade: <code>random.seed(42)</code> e <code>np.random.seed(42)</code>.</li> </ul>"},{"location":"randomforest/main/#3-divisao-dos-dados","title":"3) Divis\u00e3o dos Dados","text":"<ul> <li>Estrat\u00e9gia: embaralhamento de \u00edndices + split manual.</li> <li>Propor\u00e7\u00e3o: 80% treino | 20% valida\u00e7\u00e3o/teste.</li> <li>Motivo: avaliar o desempenho em registros nunca vistos.</li> </ul>"},{"location":"randomforest/main/#4-treinamento-do-modelo-implementacao-propria","title":"4) Treinamento do Modelo (Implementa\u00e7\u00e3o Pr\u00f3pria)","text":"<ul> <li>Algoritmo: Random Forest manual (conjunto de \u00e1rvores de decis\u00e3o).</li> <li>Crit\u00e9rio: impureza de Gini.</li> <li>Amostragem: bootstrap por \u00e1rvore; sele\u00e7\u00e3o aleat\u00f3ria de atributos por divis\u00e3o.</li> <li>Par\u00e2metros principais:</li> <li><code>n_estimators = 15</code></li> <li><code>max_depth = 6</code></li> <li><code>min_samples_split = 4</code></li> <li><code>max_features = \"sqrt\"</code></li> </ul>"},{"location":"randomforest/main/#5-avaliacao-do-modelo","title":"5) Avalia\u00e7\u00e3o do Modelo","text":""},{"location":"randomforest/main/#acuracia","title":"Acur\u00e1cia","text":"<ul> <li>Valida\u00e7\u00e3o/Teste: 0,774 (77,4%).</li> </ul>"},{"location":"randomforest/main/#relatorio-de-classificacao","title":"Relat\u00f3rio de Classifica\u00e7\u00e3o","text":"Classe Precision Recall F1-Score Suporte 0 (sem diabetes) 0,900 0,783 0,837 46 1 (com diabetes) 0,545 0,750 0,632 16 Acur\u00e1cia 0,774 62 M\u00e9dia macro 0,723 0,766 0,734 62 M\u00e9dia ponderada 0,809 0,774 0,784 62"},{"location":"randomforest/main/#matriz-de-confusao","title":"Matriz de Confus\u00e3o","text":"Previsto 0 Previsto 1 Real 0 36 10 Real 1 4 12 <ul> <li>Acerta bem a classe 0 (precision alta).</li> <li>Para a classe 1, o recall \u00e9 0,75 (identifica 75% dos casos positivos), com mais falsos positivos.</li> </ul>"},{"location":"randomforest/main/#importancia-das-variaveis-sklearn-para-interpretacao","title":"Import\u00e2ncia das Vari\u00e1veis (sklearn para interpreta\u00e7\u00e3o)","text":"Vari\u00e1vel Import\u00e2ncia Glucose 0,274 BMI 0,148 Age 0,147 DiabetesPedigreeFunction 0,112 Pregnancies 0,109 BloodPressure 0,085 SkinThickness 0,066 Insulin 0,059 <p>A glicose \u00e9 o preditor mais relevante, seguida por IMC e idade, o que \u00e9 consistente com a literatura cl\u00ednica.</p>"},{"location":"randomforest/main/#6-relatorio-final-e-melhorias","title":"6) Relat\u00f3rio Final e Melhorias","text":"<p>Resumo: O Random Forest implementado atingiu 77,4% de acur\u00e1cia, com bom desempenho geral e interpreta\u00e7\u00e3o via import\u00e2ncia de features. O modelo equilibra vi\u00e9s e vari\u00e2ncia gra\u00e7as ao comit\u00ea de \u00e1rvores e \u00e0 amostragem de atributos.</p> <p>Poss\u00edveis melhorias: - Balanceamento de classes (SMOTE, oversampling ou class weights). - Explorar mais \u00e1rvores e profundidade maior com valida\u00e7\u00e3o cruzada. - Avaliar ROC/AUC, precis\u00e3o-recall e threshold tuning conforme o custo de erros. - Testar padroniza\u00e7\u00e3o seletiva e engenharia de atributos (ex.: intera\u00e7\u00f5es cl\u00ednicas). - Comparar com modelos baseline (Log\u00edstica, KNN, XGBoost) e com grid search.</p>"},{"location":"roteiro1/main/","title":"Roteiro 1","text":""},{"location":"roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiro1/main/#app","title":"App","text":""},{"location":"roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"roteiro2/main/","title":"Roteiro 2","text":""},{"location":"roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiro3/main/","title":"Roteiro 3","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> </p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> <p></p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiro4/main/","title":"Roteiro 4","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-10-28T15:26:22.833290 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ 2025-10-28T15:26:23.660438 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"svm/main/","title":"svm","text":"output code <pre><code>import numpy as np\nimport pandas as pd\nfrom scipy import optimize\nimport matplotlib.pyplot as plt\n\n# ===== 1) Ler o CSV =====\ndf = pd.read_csv('https://raw.githubusercontent.com/marcelademartini/Machine-Learning-1/refs/heads/main/Testing.csv')\n\n# ===== 2) Selecionar duas features num\u00e9ricas para visualiza\u00e7\u00e3o =====\n# (exemplo: duas primeiras colunas, mas voc\u00ea pode trocar pelos nomes)\nX = df.iloc[:, :2].values  \n\n# ===== 3) Definir a coluna alvo =====\ntarget = 'Outcome' if 'Outcome' in df.columns else df.columns[-1]\ny_raw = df[target]\n\n# Converter o alvo para -1 e +1\ny = np.where(y_raw == y_raw.unique()[0], -1, 1)\n\n# ===== 4) RBF kernel =====\ndef rbf_kernel(x1, x2, sigma=1):\n    return np.exp(-np.linalg.norm(x1 - x2)**2 / (2 * sigma**2))\n\n# ===== 5) Kernel matrix =====\ndef kernel_matrix(X, kernel, sigma):\n    n = X.shape[0]\n    K = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            K[i, j] = kernel(X[i], X[j], sigma)\n    return K\n\nK = kernel_matrix(X, rbf_kernel, 1)\n\n# ===== 6) Fun\u00e7\u00f5es de otimiza\u00e7\u00e3o =====\nP = np.outer(y, y) * K\n\ndef objective(alpha):\n    return 0.5 * np.dot(alpha, np.dot(P, alpha)) - np.sum(alpha)\n\ndef constraint(alpha):\n    return np.dot(alpha, y)\n\ncons = {'type': 'eq', 'fun': constraint}\nbounds = [(0, None) for _ in range(len(y))]\nalpha0 = np.zeros(len(y))\n\n# ===== 7) Resolver o problema dual =====\nres = optimize.minimize(objective, alpha0, method='SLSQP', bounds=bounds, constraints=cons)\nalpha = res.x\n\n# ===== 8) Vetores de suporte =====\nsv_threshold = 1e-5\nsv_idx = alpha &gt; sv_threshold\n\n# ===== 9) Calcular bias (b) =====\ni = np.where(sv_idx)[0][0]\nb = y[i] - np.dot(alpha * y, K[i, :])\n\n# ===== 10) Fun\u00e7\u00e3o de predi\u00e7\u00e3o =====\ndef predict(x):\n    kx = np.array([rbf_kernel(x, xi, sigma=1) for xi in X])\n    return np.dot(alpha * y, kx) + b\n\n# ===== 11) Plot da fronteira =====\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n\nZ = np.array([predict(np.array([r, c])) for r, c in zip(xx.ravel(), yy.ravel())])\nZ = Z.reshape(xx.shape)\n\nplt.figure(figsize=(8, 6))\nplt.contourf(xx, yy, Z, levels=[-np.inf, 0, np.inf], colors=['#FFDDDD', '#DDDDFF'], alpha=0.8)\nplt.contour(xx, yy, Z, levels=[0], colors='k', linestyles='--')\nplt.scatter(X[y == -1, 0], X[y == -1, 1], c='red', label='Class -1')\nplt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', label='Class +1')\nplt.scatter(X[sv_idx, 0], X[sv_idx, 1], s=100, facecolors='none', edgecolors='k', label='Support Vectors')\nplt.title('SVM com Kernel RBF (dados do CSV)')\nplt.xlabel(df.columns[0])\nplt.ylabel(df.columns[1])\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}